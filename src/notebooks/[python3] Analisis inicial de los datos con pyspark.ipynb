{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis inicial de datos con Spark\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "Para la entrega del dise√±o inicial debemos tener explicatados en el documentos los siguiente pasos:\n",
    "\n",
    "1- Clasificar el problema. Que tipo de problema tenemos? Regresion o clasificacion? Por que? <br>\n",
    "\n",
    "2- Tenemos los datos. <br>\n",
    "2.1 Hay que depurarlos. <br>\n",
    "2.2 Detectar y eliminar anomalias <br>\n",
    "2.3 Valores faltantes para ciertos atributos <br>\n",
    "\n",
    "3- Explorar datos (no se procesan) <br>\n",
    "3.1 Analizar la estructura <br>\n",
    "3.2 Navegar datos <br>\n",
    "3.3 Resumen estadistico. <br>\n",
    "3.4 Visualizar datos <br>\n",
    "\n",
    "4- Aplicar a los datos el algoritmo necesario <br>\n",
    "\n",
    "5- Comunicar resultados <br>\n",
    "\n",
    "Una de las herramientas que aprendimos y nos resulta sencilla es el Map-Reduce de Spark.<br>\n",
    "En el caso de necesitar graficos podemos pedirle al Spark Context que nos devuelva los datos y luego se los pasamos a una libreria de ploteo de Python3.\n",
    "\n",
    "\n",
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')    \n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark_csv as pycsv\n",
    "sc.addPyFile('pyspark_csv.py')\n",
    "plaintext_rdd = sc.textFile('data/train.csv')\n",
    "dataframe = pycsv.csvToDataFrame(sqlCtx, plaintext_rdd, parseDate=False)\n",
    "\n",
    "data = dataframe.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67726"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = data.map(lambda row: row.ProductId).distinct()\n",
    "products.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 productos con mas reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B007JFMH8M', 714),\n",
       " ('B003B3OOPA', 511),\n",
       " ('B0026RQTGE', 509),\n",
       " ('B002QWP8H0', 508),\n",
       " ('B002QWP89S', 499),\n",
       " ('B002QWHJOU', 493),\n",
       " ('B0026KNQSA', 468),\n",
       " ('B001RVFEP2', 456),\n",
       " ('B007M83302', 454),\n",
       " ('B0013NUGDE', 451),\n",
       " ('B006HYLW32', 450),\n",
       " ('B001EO5Q64', 449),\n",
       " ('B000VK8AVK', 449),\n",
       " ('B0026KPDG8', 448),\n",
       " ('B007M832YY', 444),\n",
       " ('B000KV7ZGQ', 441),\n",
       " ('B005K4Q1YA', 440),\n",
       " ('B005K4Q4LK', 435),\n",
       " ('B000KV61FC', 432),\n",
       " ('B000NMJWZO', 432)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda row: (row.ProductId, 1)).reduceByKey(lambda a, b: a+b).takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 productos con mayor calificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B003XEG95U', (5, 1)),\n",
       " ('B004W0W264', (15, 3)),\n",
       " ('B007Y4D6W4', (5, 1)),\n",
       " ('B0000W2T0C', (5, 1)),\n",
       " ('B001BYEHBW', (5, 1)),\n",
       " ('B001E52ZQW', (15, 3)),\n",
       " ('B000F1Z66M', (5, 1)),\n",
       " ('B003PZY08U', (5, 1)),\n",
       " ('B0009BLNSS', (5, 1)),\n",
       " ('B002I7OP0E', (5, 1)),\n",
       " ('B0027E2MT4', (10, 2)),\n",
       " ('B007KWX7QK', (5, 1)),\n",
       " ('B000LKX9D4', (5, 1)),\n",
       " ('B002LFGNXA', (5, 1)),\n",
       " ('B003EI7V8O', (10, 2)),\n",
       " ('B001SB4IOY', (15, 3)),\n",
       " ('B000V1JU7M', (10, 2)),\n",
       " ('B001I4EDGO', (5, 1)),\n",
       " ('B007ZZQTS0', (5, 1)),\n",
       " ('B003WRLNO0', (5, 1))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda row: (row.ProductId, (row.Prediction, 1)))\\\n",
    "    .reduceByKey(lambda a,b: (a[0]+b[0],a[1]+b[1]))\\\n",
    "    .takeOrdered(20, key = lambda x: -(x[1][0]*100/x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.flatMap(lambda row: (row.Text.split())).map(lambda row: (row, 1)).reduceByKey(lambda a, b: a+b).takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
